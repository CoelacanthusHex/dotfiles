# Name: Coelacanthus Performance Optimization sysctl Configuration
# Author: Coelacanthus
# SPDX-License-Identifier: GPL-3.0-or-later
# Date Created: 2022-09-25
# Last Updated: 2022-09-25

########## Kernel ##########

# allow for more PIDs
# this value can be up to:
#   - 32768 (2^15) on a 32-bit system
#   - 4194304 (2^22) on a 64-bit system
kernel.pid_max = 4194304

########## File System ##########

# increase system file descriptor limit
# this value can be up to:
#   - 2147483647 (0x7fffffff) on a 32-bit system
#   - 9223372036854775807 (0x7fffffffffffffff) on a 64-bit system
# be aware that the Linux kernel documentation suggests that inode-max should be 3-4 times
#   larger than this value
fs.file-max = 9223372036854775807

# increase the amount of files that can be watched
# each file watch handle takes 1080 bytes
# up to 540 MiB of memory will be consumed if all 524288 handles are used
fs.inotify.max_user_watches = 524288

########## Networking ##########

# increase the maximum length of processor input queues
net.core.netdev_max_backlog = 250000

# increase TCP max buffer size setable using setsockopt()
net.core.rmem_default = 8388608
net.core.wmem_default = 8388608
net.core.rmem_max = 536870912
net.core.wmem_max = 536870912
net.core.optmem_max = 65536

# queue disciplines
# available: pfifo_fast(default) fq codel fq_codel cake(4.19)
# https://www.starduster.me/2020/03/02/linux-network-tuning-kernel-parameter/#netcoredefault_qdisc
net.core.default_qdisc = cake

########## IPv4 Networking ##########

# TCP Congestion Control Algorithm
# available: reno cubic bbr bbr2 hybla highspeed htcp veno westwood vegas
# cubic is default algorithm on Linux since 2.6.19
# westwood is suitable for wireless networks but cannot distinguish between network congestion and wireless jitter, and has low universality
# https://www.starduster.me/2020/03/02/linux-network-tuning-kernel-parameter/#netipv4tcp_congestion_control
# https://aws.amazon.com/cn/blogs/china/talking-about-network-optimization-from-the-flow-control-algorithm/
# https://toonk.io/tcp-bbr-exploring-tcp-congestion-control/index.html
# https://dropbox.tech/infrastructure/evaluating-bbrv2-on-the-dropbox-edge-network
# https://blog.csdn.net/dog250/article/details/120336563
# https://blog.csdn.net/dog250/article/details/113803334
# NOTE: linux-zen use BBRv3 for tcp_bbr.ko since 6.5
# https://github.com/zen-kernel/zen-kernel/commit/bcb27e4adacda606c76349bfba3305db6ea83887
# https://github.com/zen-kernel/zen-kernel/issues/324
net.ipv4.tcp_congestion_control = bbr

# increase system IP port limits
# This is not a fundamental solution, but it can alleviate the problem that the
# accumulation of sockets in the TIME WAIT state leads to the inability to establish
# external connections
# https://www.starduster.me/2020/03/02/linux-network-tuning-kernel-parameter/#netipv4ip_local_port_range
net.ipv4.ip_local_port_range = 4096 65535

# enabling SACK can improve congestion control and throughput
# but it could also be leveraged to exhaust system resources
# commonly exploited and rarely used
net.ipv4.tcp_sack = 1
net.ipv4.tcp_dsack = 1
net.ipv4.tcp_fack = 1

# SSR could impact TCP's performance on a fixed-speed network (e.g., wired)
#   but it could be helpful on a variable-speed network (e.g., LTE)
# uncomment this if you are on a fixed-speed network
net.ipv4.tcp_slow_start_after_idle = 0

# increase memory thresholds to prevent packet dropping
# the maximum buffer size is 536870912 bytes (512 MiB)
net.ipv4.tcp_rmem = 8192 262144 536870912
net.ipv4.tcp_wmem = 4096 16384 536870912
# reduce the maximum window size to 128 MiB to reduce TCP receive queue collapse
#   (see https://blog.cloudflare.com/optimizing-tcp-for-high-throughput-and-low-latency)
net.ipv4.tcp_adv_win_scale = -2
net.ipv4.tcp_collapse_max_bytes = 6291456
# limit the size of unsent bytes in the write queue to prevent bufferbloat
net.ipv4.tcp_notsent_lowat = 131072
